{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1: The Machine Learning Landscape\n",
    "\n",
    "## 1. Chapter Overview\n",
    "**Goal:** This chapter provides a high-level overview of Machine Learning (ML), defining what it is, why it is useful, and categorizing the various types of ML systems. It also covers the typical workflow of an ML project and the primary challenges faced by practitioners.\n",
    "\n",
    "**Key Concepts:**\n",
    "* Definition of Machine Learning.\n",
    "* Supervised vs. Unsupervised Learning.\n",
    "* Batch vs. Online Learning.\n",
    "* Instance-based vs. Model-based Learning.\n",
    "* Overfitting and Underfitting.\n",
    "\n",
    "**Practical Skills:**\n",
    "* Loading and preparing data using Pandas.\n",
    "* Training a simple Linear Regression model using Scikit-Learn.\n",
    "* Comparing Linear Regression with k-Nearest Neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Theoretical Explanation\n",
    "\n",
    "### What is Machine Learning?\n",
    "Machine Learning is the science of programming computers to learn from data. Instead of explicitly hard-coding rules (e.g., \"if email contains 'free', mark as spam\"), an ML system learns patterns from examples (training data) to make predictions on new data.\n",
    "\n",
    "### Types of Machine Learning Systems\n",
    "ML systems are generally classified by three criteria:\n",
    "\n",
    "1.  **Human Supervision**:\n",
    "    * **Supervised Learning:** The training data includes labels (the desired solutions). Examples: Linear Regression, Spam Classification.\n",
    "    * **Unsupervised Learning:** The training data is unlabeled. The system tries to learn without a teacher. Examples: Clustering, Dimensionality Reduction.\n",
    "    * **Semi-supervised Learning:** A mix of a small amount of labeled data and a lot of unlabeled data.\n",
    "    * **Reinforcement Learning:** An agent observes an environment, selects actions, and gets rewards or penalties in return. It learns the best strategy (policy) to maximize rewards.\n",
    "\n",
    "2.  **Incremental Learning**:\n",
    "    * **Batch Learning:** The system is incapable of learning incrementally. It must be trained using all available data. This takes time and resources, so it is typically done offline.\n",
    "    * **Online Learning:** The system learns incrementally by feeding it data instances sequentially, either individually or in small groups (mini-batches). Good for systems that receive data as a continuous flow.\n",
    "\n",
    "3.  **Generalization Approach**:\n",
    "    * **Instance-based Learning:** The system learns the examples by heart, then generalizes to new cases by comparing them to the learned examples using a similarity measure.\n",
    "    * **Model-based Learning:** The system builds a model of the examples (like a formula) and uses that model to make predictions.\n",
    "\n",
    "### Main Challenges\n",
    "* **Insufficient Quantity of Training Data:** ML algorithms generally need a lot of data to work well.\n",
    "* **Nonrepresentative Training Data:** The training data must be representative of the new cases you want to generalize to (avoiding sampling bias).\n",
    "* **Poor-Quality Data:** Errors, outliers, and noise make it hard for the system to detect patterns.\n",
    "* **Irrelevant Features:** Garbage in, garbage out. Success depends on *Feature Engineering* (selecting good features).\n",
    "* **Overfitting:** The model performs well on the training data but generalizes poorly. It means the model is too complex relative to the amount and noisiness of the training data.\n",
    "* **Underfitting:** The model is too simple to learn the underlying structure of the data.\n",
    "\n",
    "### Testing and Validating\n",
    "To estimate how well a model will perform on new instances, you split your data into:\n",
    "1.  **Training Set:** Used to train the model.\n",
    "2.  **Test Set:** Used to evaluate the model.\n",
    "\n",
    "The error rate on new cases is called the *generalization error*. If the training error is low but the generalization error is high, the model is overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Code Reproduction\n",
    "\n",
    "In this section, we will reproduce the example from the book: **\"Does money make people happier?\"**\n",
    "We will try to predict Life Satisfaction based on GDP per capita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.linear_model\n",
    "import sklearn.neighbors\n",
    "\n",
    "# Ensure plots are displayed inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation Helper Function\n",
    "The book mentions a `prepare_country_stats` function to merge the OECD Life Satisfaction data and the IMF GDP data. We define it here to make the code runnable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_country_stats(oecd_bli, gdp_per_capita):\n",
    "    # Filter for 'Total' inequality (TOT)\n",
    "    oecd_bli = oecd_bli[oecd_bli[\"INEQUALITY\"]==\"TOT\"]\n",
    "    # Pivot the table to have countries as rows and indicators as columns\n",
    "    oecd_bli = oecd_bli.pivot(index=\"Country\", columns=\"Indicator\", values=\"Value\")\n",
    "    \n",
    "    # Rename the GDP column for clarity\n",
    "    gdp_per_capita.rename(columns={\"2015\": \"GDP per capita\"}, inplace=True)\n",
    "    gdp_per_capita.set_index(\"Country\", inplace=True)\n",
    "    \n",
    "    # Merge the two datasets on Country\n",
    "    full_country_stats = pd.merge(left=oecd_bli, right=gdp_per_capita,\n",
    "                                  left_index=True, right_index=True)\n",
    "    \n",
    "    # Sort by GDP\n",
    "    full_country_stats.sort_values(by=\"GDP per capita\", inplace=True)\n",
    "    \n",
    "    # Return only the relevant columns for our simple model\n",
    "    return full_country_stats[[\"GDP per capita\", \"Life satisfaction\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data\n",
    "Note: In a real environment, ensure `oecd_bli_2015.csv` and `gdp_per_capita.csv` are in your working directory. For this notebook, we assume the files exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "# Note: These URLs are placeholders for the actual data sources used in the book repo\n",
    "try:\n",
    "    oecd_bli = pd.read_csv(\"https://raw.githubusercontent.com/ageron/handson-ml2/master/datasets/lifesat/oecd_bli_2015.csv\", thousands=',')\n",
    "    gdp_per_capita = pd.read_csv(\"https://raw.githubusercontent.com/ageron/handson-ml2/master/datasets/lifesat/gdp_per_capita.csv\", thousands=',', delimiter='\\t', encoding='latin1', na_values=\"n/a\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "\n",
    "# Prepare the data\n",
    "country_stats = prepare_country_stats(oecd_bli, gdp_per_capita)\n",
    "X = np.c_[country_stats[\"GDP per capita\"]]\n",
    "y = np.c_[country_stats[\"Life satisfaction\"]]\n",
    "\n",
    "# Visualize the data\n",
    "country_stats.plot(kind='scatter', x=\"GDP per capita\", y='Life satisfaction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Linear Regression Model\n",
    "We select a linear model because the data appears to have a linear trend (life satisfaction goes up as GDP goes up)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a linear model\n",
    "model = sklearn.linear_model.LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y)\n",
    "\n",
    "# Make a prediction for Cyprus\n",
    "X_new = [[22587]]  # Cyprus's GDP per capita\n",
    "print(f\"Prediction for Cyprus (Linear Regression): {model.predict(X_new)[0][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a k-Nearest Neighbors Model\n",
    "Alternatively, we can use an instance-based learning algorithm. If we look at the countries closest to Cyprus in terms of GDP, we can average their life satisfaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a k-Nearest Neighbors regression model\n",
    "clf = sklearn.neighbors.KNeighborsRegressor(n_neighbors=3)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Make a prediction for Cyprus\n",
    "print(f\"Prediction for Cyprus (k-NN): {clf.predict(X_new)[0][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Step-by-Step Explanation\n",
    "\n",
    "### 1. Data Loading and Preparation\n",
    "**Input:** Two CSV files containing OECD life satisfaction data and IMF GDP data.\n",
    "**Process:** \n",
    "We use `pandas` to read the CSV files. The `prepare_country_stats` function performs an inner join on the country names. This ensures we only use countries for which we have both GDP and Life Satisfaction data. We then sort the data by GDP.\n",
    "**Output:** `X` (Feature matrix containing GDP) and `y` (Label vector containing Life Satisfaction).\n",
    "\n",
    "### 2. Model Selection\n",
    "**Concept:** Model-based Learning vs. Instance-based Learning.\n",
    "* **Linear Regression:** We assume a mathematical relationship ($Life\\_Sat = \\theta_0 + \\theta_1 \\times GDP$). The `fit()` method calculates the optimal parameters ($\\theta_0$ and $\\theta_1$) that minimize the error between the model's predictions and the actual data.\n",
    "* **k-Nearest Neighbors:** This is instance-based. The model doesn't learn a formula. Instead, when we ask for a prediction for Cyprus ($22,587), it finds the 3 countries with the closest GDP in the training data and returns their average life satisfaction.\n",
    "\n",
    "### 3. Training (`fit`)\n",
    "The `.fit(X, y)` command triggers the learning process. \n",
    "* For Linear Regression, it solves a mathematical equation (Normal Equation or Gradient Descent) to find the best line.\n",
    "* For k-NN, it simply stores the data efficiently to allow for fast distance calculations later.\n",
    "\n",
    "### 4. Prediction (`predict`)\n",
    "We provide a new instance (`X_new` representing Cyprus). The models output a floating-point number representing the predicted life satisfaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Chapter Summary\n",
    "\n",
    "* **Machine Learning** is about building systems that learn from data rather than explicit rules.\n",
    "* **Workflow:** A typical project involves fetching data, cleaning it, selecting a model, training it, and using it for prediction.\n",
    "* **Model Selection:** You can choose between model-based approaches (like Linear Regression) which find a mathematical trend, or instance-based approaches (like k-NN) which rely on similarity to existing data.\n",
    "* **Data Matters:** The quality and quantity of data are often more important than the sophistication of the algorithm. Bad data (outliers, missing values) or bad features lead to bad models.\n",
    "* **Evaluation:** Always set aside a **Test Set** to evaluate how your model performs on unseen data to avoid overfitting."
   ]
  }
 ]
}
