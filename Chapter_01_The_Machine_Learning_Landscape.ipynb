{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Chapter 1: The Machine Learning Landscape\n",
        "\n",
        "## 1. Chapter Overview\n",
        "**Goal:** This chapter provides a high-level overview of Machine Learning (ML), defining what it is, why it is useful, and categorizing the various types of ML systems. It also covers the typical workflow of an ML project and the primary challenges faced by practitioners.\n",
        "\n",
        "**Key Concepts:**\n",
        "* Definition of Machine Learning.\n",
        "* Supervised vs. Unsupervised Learning.\n",
        "* Batch vs. Online Learning.\n",
        "* Instance-based vs. Model-based Learning.\n",
        "* Overfitting and Underfitting.\n",
        "\n",
        "**Practical Skills:**\n",
        "* Loading and preparing data using Pandas.\n",
        "* Training a simple Linear Regression model using Scikit-Learn.\n",
        "* Comparing Linear Regression with k-Nearest Neighbors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Theoretical Explanation\n",
        "\n",
        "### What is Machine Learning?\n",
        "Machine Learning is the science of programming computers to learn from data. Instead of explicitly hard-coding rules (e.g., \"if email contains 'free', mark as spam\"), an ML system learns patterns from examples (training data) to make predictions on new data.\n",
        "\n",
        "### Types of Machine Learning Systems\n",
        "ML systems are generally classified by three criteria:\n",
        "\n",
        "1.  **Human Supervision**:\n",
        "    * **Supervised Learning:** The training data includes labels (the desired solutions). Examples: Linear Regression, Spam Classification.\n",
        "    * **Unsupervised Learning:** The training data is unlabeled. The system tries to learn without a teacher. Examples: Clustering, Dimensionality Reduction.\n",
        "    * **Semi-supervised Learning:** A mix of a small amount of labeled data and a lot of unlabeled data.\n",
        "    * **Reinforcement Learning:** An agent observes an environment, selects actions, and gets rewards or penalties in return. It learns the best strategy (policy) to maximize rewards.\n",
        "\n",
        "2.  **Incremental Learning**:\n",
        "    * **Batch Learning:** The system is incapable of learning incrementally. It must be trained using all available data. This takes time and resources, so it is typically done offline.\n",
        "    * **Online Learning:** The system learns incrementally by feeding it data instances sequentially, either individually or in small groups (mini-batches). Good for systems that receive data as a continuous flow.\n",
        "\n",
        "3.  **Generalization Approach**:\n",
        "    * **Instance-based Learning:** The system learns the examples by heart, then generalizes to new cases by comparing them to the learned examples using a similarity measure.\n",
        "    * **Model-based Learning:** The system builds a model of the examples (like a formula) and uses that model to make predictions.\n",
        "\n",
        "### Main Challenges\n",
        "* **Insufficient Quantity of Training Data:** ML algorithms generally need a lot of data to work well.\n",
        "* **Nonrepresentative Training Data:** The training data must be representative of the new cases you want to generalize to (avoiding sampling bias).\n",
        "* **Poor-Quality Data:** Errors, outliers, and noise make it hard for the system to detect patterns.\n",
        "* **Irrelevant Features:** Garbage in, garbage out. Success depends on *Feature Engineering* (selecting good features).\n",
        "* **Overfitting:** The model performs well on the training data but generalizes poorly. It means the model is too complex relative to the amount and noisiness of the training data.\n",
        "* **Underfitting:** The model is too simple to learn the underlying structure of the data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Code Reproduction\n",
        "\n",
        "We will reproduce the \"Money and Happiness\" example. We start with the standard setup found in the book's notebooks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup\n",
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# To plot pretty figures directly within Jupyter\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Loading and Preparation\n",
        "We define the function `prepare_country_stats` to merge OECD life satisfaction data and IMF GDP data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def prepare_country_stats(oecd_bli, gdp_per_capita):\n",
        "    oecd_bli = oecd_bli[oecd_bli[\"INEQUALITY\"]==\"TOT\"]\n",
        "    oecd_bli = oecd_bli.pivot(index=\"Country\", columns=\"Indicator\", values=\"Value\")\n",
        "    gdp_per_capita.rename(columns={\"2015\": \"GDP per capita\"}, inplace=True)\n",
        "    gdp_per_capita.set_index(\"Country\", inplace=True)\n",
        "    full_country_stats = pd.merge(left=oecd_bli, right=gdp_per_capita,\n",
        "                                  left_index=True, right_index=True)\n",
        "    full_country_stats.sort_values(by=\"GDP per capita\", inplace=True)\n",
        "    remove_indices = [0, 1, 6, 8, 33, 34, 35]\n",
        "    keep_indices = list(set(range(36)) - set(remove_indices))\n",
        "    return full_country_stats[[\"GDP per capita\", \"Life satisfaction\"]].iloc[keep_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the data\n",
        "import urllib.request\n",
        "\n",
        "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
        "os.makedirs(\"datasets/lifesat\", exist_ok=True)\n",
        "\n",
        "for filename in (\"oecd_bli_2015.csv\", \"gdp_per_capita.csv\"):\n",
        "    print(\"Downloading\", filename)\n",
        "    url = DOWNLOAD_ROOT + \"datasets/lifesat/\" + filename\n",
        "    urllib.request.urlretrieve(url, \"datasets/lifesat/\" + filename)\n",
        "\n",
        "oecd_bli = pd.read_csv(\"datasets/lifesat/oecd_bli_2015.csv\", thousands=',')\n",
        "gdp_per_capita = pd.read_csv(\"datasets/lifesat/gdp_per_capita.csv\", thousands=',', delimiter='\\t',\n",
        "                             encoding='latin1', na_values=\"n/a\")\n",
        "\n",
        "# Prepare the data\n",
        "country_stats = prepare_country_stats(oecd_bli, gdp_per_capita)\n",
        "X = np.c_[country_stats[\"GDP per capita\"]]\n",
        "y = np.c_[country_stats[\"Life satisfaction\"]]\n",
        "\n",
        "# Visualize the data\n",
        "country_stats.plot(kind='scatter', x=\"GDP per capita\", y='Life satisfaction')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training and Prediction\n",
        "We will now train a **Linear Regression** model and make a prediction for Cyprus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sklearn.linear_model\n",
        "\n",
        "# Select a linear model\n",
        "model = sklearn.linear_model.LinearRegression()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y)\n",
        "\n",
        "# Make a prediction for Cyprus\n",
        "X_new = [[22587]]  # Cyprus's GDP per capita\n",
        "print(f\"Prediction for Cyprus (Linear Regression): {model.predict(X_new)[0][0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Alternative Model: k-Nearest Neighbors\n",
        "Using an instance-based learning algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sklearn.neighbors\n",
        "\n",
        "# Select a k-Nearest Neighbors regression model\n",
        "model_knn = sklearn.neighbors.KNeighborsRegressor(n_neighbors=3)\n",
        "\n",
        "# Train the model\n",
        "model_knn.fit(X, y)\n",
        "\n",
        "# Make a prediction for Cyprus\n",
        "print(f\"Prediction for Cyprus (k-NN): {model_knn.predict(X_new)[0][0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Step-by-Step Explanation\n",
        "\n",
        "### 1. Data Pipeline\n",
        "**Input:** Two CSV files (OECD Life Satisfaction & IMF GDP).\n",
        "**Process:** \n",
        "1.  **Ingestion:** We download the raw CSVs from the book's repository.\n",
        "2.  **Cleaning:** The `prepare_country_stats` function filters the data, handles missing values, and merges the two tables based on 'Country'.\n",
        "3.  **Visualization:** We plot the data to visually confirm a linear trend.\n",
        "**Output:** `X` (GDP) and `y` (Life Satisfaction).\n",
        "\n",
        "### 2. Model Training (`fit`)\n",
        "* **Linear Regression:** The algorithm finds the parameters $\\theta_0$ and $\\theta_1$ that minimize the cost function (MSE). It effectively draws the \"best fit\" line through the data points.\n",
        "* **k-NN:** The algorithm memorizes the training instances. It does not create a formula.\n",
        "\n",
        "### 3. Prediction (`predict`)\n",
        "When we ask for a prediction for Cyprus ($22,587):\n",
        "* **Linear Model:** Inputs the value into the formula: $LifeSatisfaction = \\theta_0 + \\theta_1 \\times 22587$.\n",
        "* **k-NN Model:** Finds the 3 countries with GDP closest to $22,587 and averages their life satisfaction scores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Chapter Summary\n",
        "\n",
        "* **Machine Learning** is about building systems that learn from data rather than explicit rules.\n",
        "* **Workflow:** A typical project involves fetching data, cleaning it, selecting a model, training it, and using it for prediction.\n",
        "* **Model Selection:** You can choose between model-based approaches (like Linear Regression) which find a mathematical trend, or instance-based approaches (like k-NN) which rely on similarity to existing data.\n",
        "* **Data Matters:** The quality and quantity of data are often more important than the sophistication of the algorithm. Bad data (outliers, missing values) or bad features lead to bad models.\n",
        "* **Evaluation:** Always set aside a **Test Set** to evaluate how your model performs on unseen data to avoid overfitting."
      ]
    }
  ]
}
