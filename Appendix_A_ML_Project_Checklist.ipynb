{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix A: Machine Learning Project Checklist\n",
    "\n",
    "## 1. Overview\n",
    "**Goal:** While the previous chapters focused on algorithms and code, this notebook focuses on **Process**. This is a comprehensive checklist derived from the book to guide you through any Machine Learning project, ensuring you don't miss critical stepsâ€”from framing the problem to deploying the model.\n",
    "\n",
    "**The 8 Main Steps:**\n",
    "1.  **Frame the Problem:** Define the objective and look at the big picture.\n",
    "2.  **Get the Data:** Find, gather, and explore the data.\n",
    "3.  **Explore the Data:** Gain insights and visualize correlations.\n",
    "4.  **Prepare the Data:** Clean and transform the data for ML algorithms.\n",
    "5.  **Shortlist Models:** Train many quick-and-dirty models to find promising candidates.\n",
    "6.  **Fine-Tune:** Tune hyperparameters and combine models.\n",
    "7.  **Present:** Document and communicate your solution.\n",
    "8.  **Launch:** Deploy, monitor, and maintain the system.\n",
    "\n",
    "**Practical Utility:**\n",
    "* This notebook includes **Reusable Code Templates** for common tasks like data downloading, structure setup, and correlation analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Standard Imports for any ML Project\n",
    "import sys\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Best practice: Set seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"Project Environment Setup Complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Frame the Problem\n",
    "\n",
    "Before touching any code, answer these questions:\n",
    "1.  **Define the Objective:** What is the business goal? (e.g., Increase revenue? Reduce spam?)\n",
    "2.  **Current Solution:** How is this problem solved currently? (e.g., Manual review? Simple rules?)\n",
    "3.  **Type of System:** \n",
    "    * Supervised, Unsupervised, or RL?\n",
    "    * Classification or Regression?\n",
    "    * Batch or Online learning?\n",
    "4.  **Performance Measure:** What metric will you use? (RMSE, Accuracy, F1-Score, ROC-AUC?)\n",
    "5.  **Assumptions:** List all assumptions and verify them if possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Get the Data\n",
    "\n",
    "Automate this step as much as possible so you can get fresh data easily.\n",
    "\n",
    "**Checklist:**\n",
    "* List the data you need and how much.\n",
    "* Find and document where to get that data.\n",
    "* Check legal obligations (privacy, copyright).\n",
    "* Create a workspace with enough storage.\n",
    "* Create a script to download the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility: Generic Data Download Function\n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "def fetch_data(url, path, filename=\"data.tgz\", extract=True):\n",
    "    \"\"\"\n",
    "    Downloads and optionally extracts a dataset.\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)\n",
    "    \n",
    "    tgz_path = os.path.join(path, filename)\n",
    "    \n",
    "    print(f\"Downloading from {url}...\")\n",
    "    urllib.request.urlretrieve(url, tgz_path)\n",
    "    print(\"Download complete.\")\n",
    "    \n",
    "    if extract:\n",
    "        print(\"Extracting...\")\n",
    "        data_tgz = tarfile.open(tgz_path)\n",
    "        data_tgz.extractall(path=path)\n",
    "        data_tgz.close()\n",
    "        print(\"Extraction complete.\")\n",
    "\n",
    "# Example usage (commented out)\n",
    "# fetch_data(\"https://example.com/data.tgz\", \"datasets/my_project\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Explore the Data\n",
    "\n",
    "Try to get insights from a field expert for this step.\n",
    "\n",
    "**Checklist:**\n",
    "* Create a copy of the data for exploration (sampling if massive).\n",
    "* Study each attribute: Name, Type (Categorical/Numerical), % Missing, Noise type, Distribution (Gaussian, Uniform, Log).\n",
    "* Visualize the data.\n",
    "* Study correlations between features and the target.\n",
    "* Identify transformations (e.g., log_transform for heavy tails)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility: Quick Exploration Helper\n",
    "def quick_explore(df, target_col=None):\n",
    "    print(\"--- Head ---\")\n",
    "    display(df.head())\n",
    "    \n",
    "    print(\"\\n--- Info ---\")\n",
    "    print(df.info())\n",
    "    \n",
    "    print(\"\\n--- Numerical Stats ---\")\n",
    "    display(df.describe())\n",
    "    \n",
    "    print(\"\\n--- Missing Values ---\")\n",
    "    print(df.isnull().sum())\n",
    "    \n",
    "    if target_col and target_col in df.columns:\n",
    "        print(f\"\\n--- Correlations with {target_col} ---\")\n",
    "        corr_matrix = df.corr(numeric_only=True)\n",
    "        print(corr_matrix[target_col].sort_values(ascending=False))\n",
    "        \n",
    "        print(\"\\n--- Scatter Matrix ---\")\n",
    "        from pandas.plotting import scatter_matrix\n",
    "        top_features = corr_matrix[target_col].sort_values(ascending=False).head(4).index\n",
    "        scatter_matrix(df[top_features], figsize=(12, 8))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Prepare the Data\n",
    "\n",
    "Work on copies of the data (keep the original clean). Write functions/pipelines.\n",
    "\n",
    "**Checklist:**\n",
    "1.  **Data Cleaning:**\n",
    "    * Fix or remove outliers.\n",
    "    * Fill missing values (`SimpleImputer`) or drop rows/cols.\n",
    "2.  **Feature Selection:** Drop attributes that provide no useful information.\n",
    "3.  **Feature Engineering:**\n",
    "    * Discretize continuous features.\n",
    "    * Add promising transformations (log, sqrt, squared).\n",
    "    * Aggregate features.\n",
    "4.  **Feature Scaling:** Standardize (`StandardScaler`) or Normalize (`MinMaxScaler`).\n",
    "5.  **Build a Pipeline:** Use `sklearn.pipeline.Pipeline` to automate this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Shortlist Promising Models\n",
    "\n",
    "Train many quick-and-dirty models from different categories (Linear, SVM, Random Forest, Neural Net).\n",
    "\n",
    "**Checklist:**\n",
    "* Train models using standard parameters.\n",
    "* Measure and compare their performance (Use N-fold Cross-Validation).\n",
    "* Analyze the most significant variables for each algorithm.\n",
    "* Analyze the types of errors the models make.\n",
    "* Shortlist the top 3-5 most promising models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility: Model Comparison Template\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def compare_models(models, X, y, cv=5, scoring='neg_mean_squared_error'):\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        scores = cross_val_score(model, X, y, cv=cv, scoring=scoring)\n",
    "        rmse_scores = np.sqrt(-scores)\n",
    "        results[name] = (rmse_scores.mean(), rmse_scores.std())\n",
    "        print(f\"{name}: Mean={rmse_scores.mean():.4f}, Std={rmse_scores.std():.4f}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Fine-Tune the System\n",
    "\n",
    "You now have a shortlist. It's time to optimize.\n",
    "\n",
    "**Checklist:**\n",
    "* **Hyperparameter Tuning:** Use `GridSearchCV` or `RandomizedSearchCV`. Don't manually tweak!\n",
    "* **Ensemble Methods:** Combine your best models. Voting, Bagging, or Stacking usually performs better than any single model.\n",
    "* **Evaluate on Test Set:** Once you are confident, run the final model on the test set to estimate the generalization error.\n",
    "* **Warning:** Do NOT tweak your model after measuring the test error to fix it. You will start overfitting the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Present Your Solution\n",
    "\n",
    "The technical part is done. Now you must sell it.\n",
    "\n",
    "**Checklist:**\n",
    "* Document what you have done.\n",
    "* Create a nice presentation. Make sure you highlight the big picture first.\n",
    "* Explain why your solution achieves the business objective.\n",
    "* Don't forget to present interesting points you noticed along the way (correlations, etc.).\n",
    "* Describe what worked and what didn't.\n",
    "* Ensure your key findings are communicated through beautiful visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Launch!\n",
    "\n",
    "Get your model ready for production.\n",
    "\n",
    "**Checklist:**\n",
    "* **Code Polish:** Ensure code is documented, tested, and follows PEP8.\n",
    "* **Deployment:** Save model (`joblib` or `SavedModel`). Deploy to REST API (TF Serving) or Cloud (GCP/AWS).\n",
    "* **Monitoring:** Write monitoring code to check your system's live performance at regular intervals and trigger alerts when it drops.\n",
    "* **Retraining:** Automate the process of retraining the model on fresh data.\n",
    "* **Archive:** Archive your models and data versions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
