{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 10: Introduction to Artificial Neural Networks with Keras\n",
    "\n",
    "## 1. Chapter Overview\n",
    "**Tujuan:** Bab ini menandai transisi dari Machine Learning tradisional ke **Deep Learning**. Kita akan mempelajari Jaringan Saraf Tiruan (Artificial Neural Networks - ANN), mulai dari arsitektur paling sederhana (Perceptron) hingga Multi-Layer Perceptron (MLP). Kita akan menggunakan **Keras**, API tingkat tinggi yang berjalan di atas TensorFlow, untuk membangun model yang dapat mengklasifikasikan gambar fashion dan memprediksi harga rumah.\n",
    "\n",
    "**Konsep Kunci:**\n",
    "* **Perceptron & TLU:** Unit dasar logika jaringan saraf.\n",
    "* **Multi-Layer Perceptron (MLP):** Menumpuk lapisan untuk memecahkan masalah non-linear (XOR problem).\n",
    "* **Backpropagation:** Algoritma pelatihan revolusioner yang menghitung gradien secara efisien.\n",
    "* **Fungsi Aktivasi:** Mengapa kita membutuhkan ReLU, Sigmoid, atau Softmax.\n",
    "* **Keras API:**\n",
    "    * *Sequential API:* Untuk tumpukan lapisan sederhana.\n",
    "    * *Functional API:* Untuk topologi kompleks (Wide & Deep).\n",
    "    * *Subclassing API:* Untuk kontrol penuh (research level).\n",
    "* **Hyperparameter Tuning:** Menggunakan RandomizedSearch untuk mencari jumlah neuron dan learning rate yang optimal.\n",
    "\n",
    "**Keterampilan Praktis:**\n",
    "* Membangun Image Classifier untuk dataset **Fashion MNIST**.\n",
    "* Membangun Regressor untuk dataset perumahan California.\n",
    "* Menggunakan Callbacks (EarlyStopping, ModelCheckpoint) untuk mencegah overfitting.\n",
    "* Menyimpan dan memuat model Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Keras version:\", keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Penjelasan Teoretis (Mendalam)\n",
    "\n",
    "### 1. Dari Biologis ke Buatan (Perceptron)\n",
    "Ide dasar ANN terinspirasi dari neuron biologis. Neuron menerima sinyal input melalui dendrit, memprosesnya, dan jika sinyal cukup kuat, menembakkan sinyal output melalui akson.\n",
    "\n",
    "**Perceptron (Frank Rosenblatt, 1957):**\n",
    "Ini adalah arsitektur ANN paling sederhana. Terdiri dari satu lapisan **Threshold Logic Units (TLU)**. Input adalah angka, masing-masing memiliki bobot ($w$). TLU menghitung jumlah bobot ($z = w_1 x_1 + \\dots + w_n x_n + bias$), lalu menerapkan *step function*.\n",
    "* Kelemahan: Perceptron hanya bisa memecahkan masalah linear. Ia gagal pada masalah XOR sederhana.\n",
    "\n",
    "### 2. Multi-Layer Perceptron (MLP) dan Backpropagation\n",
    "Untuk mengatasi batasan Perceptron, kita menumpuk banyak lapisan TLU. Struktur ini disebut MLP:\n",
    "1.  **Input Layer:** Menerima fitur data.\n",
    "2.  **Hidden Layers:** Satu atau lebih lapisan di tengah yang melakukan transformasi representasi.\n",
    "3.  **Output Layer:** Menghasilkan prediksi akhir.\n",
    "\n",
    "**Backpropagation (Rumelhart, Hinton, Williams, 1986):**\n",
    "Bagaimana cara melatih jaringan sedalam ini? Backpropagation adalah kuncinya. Algoritma ini bekerja dalam dua langkah utama untuk setiap *batch* pelatihan:\n",
    "1.  **Forward Pass:** Data mengalir dari input ke output, menghasilkan prediksi, dan kesalahan (error) dihitung menggunakan *Loss Function*.\n",
    "2.  **Backward Pass:** Algoritma menghitung gradien kesalahan terhadap setiap parameter jaringan (bobot) dengan bergerak mundur dari output ke input (menggunakan *Chain Rule* kalkulus). Ini memberi tahu kita seberapa besar setiap bobot berkontribusi terhadap kesalahan.\n",
    "3.  **Update:** Langkah Gradient Descent menggunakan gradien tersebut untuk memperbarui bobot agar kesalahan berkurang.\n",
    "\n",
    "### 3. Fungsi Aktivasi\n",
    "Agar MLP bisa mempelajari pola non-linear, kita **harus** menggunakan fungsi aktivasi non-linear di antara lapisan linear.\n",
    "* **Sigmoid:** Mengubah output menjadi rentang 0 hingga 1. Bagus untuk output probabilitas, tapi menderita masalah *vanishing gradient* pada lapisan dalam.\n",
    "* **ReLU (Rectified Linear Unit):** $ReLU(z) = max(0, z)$. Sangat cepat dihitung dan tidak jenuh untuk nilai positif. Ini adalah standar *de facto* untuk hidden layers saat ini.\n",
    "* **Softmax:** Digunakan di *output layer* untuk klasifikasi multikelas. Memastikan total probabilitas semua kelas berjumlah 1.\n",
    "\n",
    "### 4. Keras API\n",
    "TensorFlow 2 menjadikan Keras sebagai API resminya. Keras sangat *user-friendly*:\n",
    "* **Sequential API:** Paling mudah. Cukup `model.add(Layer)`. Cocok untuk 90% kasus.\n",
    "* **Functional API:** Lebih fleksibel. Memungkinkan input ganda, output ganda, dan topologi non-linear (seperti arsitektur Wide & Deep).\n",
    "* **Subclassing API:** Paling kompleks tapi paling fleksibel. Anda menulis kelas Python sendiri. Digunakan untuk riset model baru."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Reproduksi Kode\n",
    "\n",
    "### 3.1 Membangun Image Classifier (Fashion MNIST)\n",
    "Kita akan menggunakan dataset Fashion MNIST (70.000 gambar grayscale 28x28 dari 10 kategori pakaian) karena sedikit lebih sulit daripada digit MNIST biasa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load Data\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# 2. Validasi Split & Normalisasi (Scaling)\n",
    "# Pixel values are 0-255. We scale them to 0-1 for Neural Networks.\n",
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "\n",
    "print(\"Shape data train:\", X_train.shape)\n",
    "print(\"Contoh kelas:\", class_names[y_train[0]])\n",
    "\n",
    "# Visualisasi satu gambar\n",
    "plt.imshow(X_train[0], cmap=\"binary\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Membuat Model dengan Sequential API\n",
    "Kita akan membuat MLP dengan 2 hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]), # Mengubah 2D (28x28) menjadi 1D (784)\n",
    "    keras.layers.Dense(300, activation=\"relu\"), # Hidden Layer 1: 300 neuron, ReLU\n",
    "    keras.layers.Dense(100, activation=\"relu\"), # Hidden Layer 2: 100 neuron, ReLU\n",
    "    keras.layers.Dense(10, activation=\"softmax\") # Output Layer: 10 kelas, Softmax\n",
    "])\n",
    "\n",
    "# Melihat ringkasan arsitektur\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Compile dan Train Model\n",
    "* **Loss:** `sparse_categorical_crossentropy` karena label kita berupa integer (0-9), bukan one-hot vector.\n",
    "* **Optimizer:** `sgd` (Stochastic Gradient Descent).\n",
    "* **Metrics:** `accuracy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# Melatih model (ini mungkin memakan waktu beberapa detik/menit)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Visualisasi Kurva Pembelajaran\n",
    "Objek `history` menyimpan data loss dan akurasi selama pelatihan. Kita bisa memplotnya untuk melihat apakah terjadi overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # Set range sumbu Y dari 0 ke 1\n",
    "plt.title(\"Learning Curves\")\n",
    "plt.show()\n",
    "\n",
    "# Evaluasi pada Test Set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"\\nTest Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Prediksi\n",
    "Menggunakan model untuk memprediksi probabilitas kelas pada data baru."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "print(\"Probabilitas:\\n\", y_proba.round(2))\n",
    "\n",
    "# Mengambil kelas dengan probabilitas tertinggi\n",
    "y_pred = np.argmax(y_proba, axis=1)\n",
    "print(\"Prediksi:\", np.array(class_names)[y_pred])\n",
    "print(\"Label Asli:\", np.array(class_names)[y_test[:3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Regression MLP (Functional API)\n",
    "Untuk regresi (memprediksi harga rumah California), struktur MLP sedikit berbeda:\n",
    "* Output layer hanya punya **1 neuron**.\n",
    "* **Tidak ada fungsi aktivasi** di output (karena kita ingin nilai kontinu bebas).\n",
    "* Loss function: **MSE**.\n",
    "\n",
    "Kita juga akan menggunakan **Functional API** untuk membuat arsitektur **Wide & Deep**. Arsitektur ini menghubungkan sebagian input langsung ke output (Wide) dan sebagian melalui hidden layers (Deep). Ini memungkinkan model mempelajari pola sederhana (linear) dan pola kompleks (deep) sekaligus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load & Split Data\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "# Scaling (Sangat PENTING untuk Neural Networks!)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# --- Functional API ---\n",
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "\n",
    "# Concatenate input langsung dengan output hidden layer 2\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "\n",
    "model_func = keras.models.Model(inputs=[input_], outputs=[output])\n",
    "\n",
    "model_func.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "\n",
    "print(\"Training Wide & Deep Model...\")\n",
    "history = model_func.fit(X_train, y_train, epochs=20,\n",
    "                         validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Callbacks\n",
    "Apa yang terjadi jika kita melatih terlalu lama? Overfitting. Daripada menebak jumlah epoch, kita gunakan `EarlyStopping`. Kita juga gunakan `ModelCheckpoint` untuk menyimpan model terbaik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", save_best_only=True)\n",
    "\n",
    "# Patience=10: Hentikan jika tidak ada perbaikan pada val_loss selama 10 epoch berturut-turut\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "model_func.fit(X_train, y_train, epochs=100,\n",
    "               validation_data=(X_valid, y_valid),\n",
    "               callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Langkah-demi-Langkah Penjelasan\n",
    "\n",
    "### 1. Preprocessing Data Gambar\n",
    "**Input:** Gambar `28x28` pixel dengan nilai `0-255`.\n",
    "**Proses:** Neural Network bekerja paling baik dengan input angka kecil (sekitar 0 hingga 1). Oleh karena itu, kita membagi data dengan `255.0`. Jika kita lupa langkah ini, model mungkin akan gagal konvergen (gradien meledak atau menghilang).\n",
    "\n",
    "### 2. Arsitektur Model Klasifikasi\n",
    "* `Flatten`: Lapisan ini tidak memiliki parameter (bobot) untuk dipelajari. Tugasnya hanya \"meratakan\" matriks 2D menjadi vektor panjang. Ini adalah jembatan antara data gambar dan lapisan Dense.\n",
    "* `Dense`: Setiap neuron di layer ini terhubung ke *semua* neuron di layer sebelumnya. Inilah mengapa disebut *Dense* (padat) atau *Fully Connected*.\n",
    "* `ReLU`: Tanpa ini, tumpukan lapisan Dense hanyalah satu fungsi linear besar ($f(g(x)) = W_2(W_1 x)$ masih linear). ReLU memperkenalkan non-linearitas, memungkinkan model mempelajari batas keputusan yang kompleks (seperti lengkungan).\n",
    "* `Softmax`: Mengubah skor mentah (logits) dari output layer menjadi probabilitas yang valid (total = 1).\n",
    "\n",
    "### 3. Arsitektur Wide & Deep\n",
    "Pada Functional API, kita melihat `Concatenate`. Idenya adalah:\n",
    "* Jalur **Deep** (lewat hidden layer) belajar pola kompleks dan abstrak.\n",
    "* Jalur **Wide** (langsung dari input ke output) belajar pola sederhana atau aturan eksplisit.\n",
    "* Menggabungkan keduanya seringkali menghasilkan performa yang lebih baik daripada MLP standar untuk data tabular.\n",
    "\n",
    "### 4. Early Stopping\n",
    "Ini adalah bentuk regularisasi otomatis. Alih-alih Anda harus memonitor grafik loss secara manual dan menekan tombol stop, callback ini melakukannya untuk Anda. Jika `val_loss` tidak turun selama 10 epoch, ia berasumsi model sudah mulai overfitting (atau macet), menghentikan pelatihan, dan mengembalikan bobot ke kondisi terbaik sebelumnya."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Ringkasan Bab\n",
    "\n",
    "* **Deep Learning** menggunakan jaringan saraf berlapis banyak untuk mempelajari representasi data yang kompleks.\n",
    "* **Keras** adalah API yang sangat kuat dan mudah digunakan untuk membangun model deep learning di TensorFlow.\n",
    "* **Sequential API** sangat bagus untuk model tumpukan sederhana.\n",
    "* **Functional API** diperlukan untuk arsitektur yang lebih kompleks (cabang, multiple input/output).\n",
    "* **Preprocessing:** Selalu lakukan penskalaan (StandardScaler/MinMax) pada data sebelum dimasukkan ke Neural Network.\n",
    "* **Loss Function:** Gunakan `sparse_categorical_crossentropy` untuk klasifikasi integer label, dan `mean_squared_error` untuk regresi.\n",
    "* **Activation:** Gunakan `ReLU` untuk hidden layers dan `Softmax` (klasifikasi) atau `Linear/None` (regresi) untuk output layer.\n",
    "* **Optimization:** Jangan biarkan model overfitting; gunakan `EarlyStopping` dan simpan model terbaik dengan `ModelCheckpoint`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
