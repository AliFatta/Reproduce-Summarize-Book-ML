{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 17: Representation Learning and Generative Learning (Autoencoders and GANs)\n",
    "\n",
    "## 1. Chapter Overview\n",
    "**Goal:** Can machines be creative? In this chapter, we explore **Generative Learning**. We start with **Autoencoders**, which learn efficient representations (embeddings) of data by trying to copy inputs to outputs with constraints. Then we dive into **Generative Adversarial Networks (GANs)**, where two neural networks compete against each other—one trying to generate fake data, the other trying to detect it—resulting in incredibly realistic synthetic data.\n",
    "\n",
    "**Key Concepts:**\n",
    "* **Autoencoders:** Encoder (compresses) + Decoder (reconstructs).\n",
    "* **Undercomplete Autoencoders:** Forcing the network to learn the most important features by limiting the latent size.\n",
    "* **Stacked Autoencoders:** Deep networks for better feature extraction.\n",
    "* **Denoising Autoencoders:** Learning robust features by recovering clean images from noisy ones.\n",
    "* **Variational Autoencoders (VAEs):** Probabilistic autoencoders that can generate new instances by sampling from a latent distribution.\n",
    "* **GANs (Generative Adversarial Networks):** Generator vs. Discriminator game.\n",
    "* **DCGANs:** Deep Convolutional GANs for generating images.\n",
    "* **Mode Collapse:** A common failure mode where the Generator produces limited varieties of samples.\n",
    "\n",
    "**Practical Skills:**\n",
    "* Building a Stacked Autoencoder for MNIST reconstruction.\n",
    "* Visualizing the latent space (t-SNE).\n",
    "* Implementing a Variational Autoencoder to generate new digits.\n",
    "* Training a DCGAN to generate Fashion MNIST images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Theoretical Explanation (In-Depth)\n",
    "\n",
    "### 1. Autoencoders\n",
    "An Autoencoder is a neural network trained to output its input ($output = input$). This sounds trivial (the Identity function), but the catch is that we impose **constraints**.\n",
    "* **Bottleneck:** The hidden layer in the middle is much smaller than the input (e.g., input 784 $\\rightarrow$ hidden 30 $\\rightarrow$ output 784). The network *must* compress the data, learning the most efficient representation (codings).\n",
    "* **Usage:** Dimensionality Reduction, Denoising, and Pretraining for supervised tasks.\n",
    "\n",
    "### 2. Variational Autoencoders (VAEs)\n",
    "Standard Autoencoders map an input to a fixed vector. VAEs map an input to a **probability distribution** (mean $\\mu$ and variance $\\sigma$).\n",
    "* **Generation:** To generate a new digit, we sample a random vector from the learned distribution and feed it to the decoder.\n",
    "* **Loss Function:** Reconstruction Loss + KL Divergence (forces the distribution to look like a Gaussian).\n",
    "\n",
    "### 3. Generative Adversarial Networks (GANs)\n",
    "Proposed by Ian Goodfellow in 2014. It consists of two networks:\n",
    "1.  **Generator:** Takes random noise and tries to generate realistic data (fake).\n",
    "2.  **Discriminator:** Takes real data and fake data, and tries to distinguish them.\n",
    "\n",
    "**Training (Min-Max Game):**\n",
    "* The Discriminator tries to maximize its accuracy (detect fakes).\n",
    "* The Generator tries to minimize the Discriminator's accuracy (fool it).\n",
    "* Ideally, they reach an equilibrium where the generator produces perfect fakes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Code Reproduction\n",
    "\n",
    "### 3.1 Stacked Autoencoder (Dimensionality Reduction)\n",
    "We will compress Fashion MNIST from 784 dimensions down to 30, and then reconstruct it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full.astype(np.float32) / 255\n",
    "X_test = X_test.astype(np.float32) / 255\n",
    "X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]\n",
    "y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]\n",
    "\n",
    "# Stacked Autoencoder\n",
    "stacked_encoder = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(100, activation=\"selu\"),\n",
    "    keras.layers.Dense(30, activation=\"selu\"),\n",
    "])\n",
    "stacked_decoder = keras.models.Sequential([\n",
    "    keras.layers.Dense(100, activation=\"selu\", input_shape=[30]),\n",
    "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
    "    keras.layers.Reshape([28, 28])\n",
    "])\n",
    "stacked_ae = keras.models.Sequential([stacked_encoder, stacked_decoder])\n",
    "\n",
    "stacked_ae.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.SGD(learning_rate=1.5), metrics=[\"accuracy\"])\n",
    "# Note: Autoencoders are unsupervised, so y is X_train\n",
    "history = stacked_ae.fit(X_train, X_train, epochs=10, validation_data=(X_valid, X_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Reconstruction\n",
    "def plot_image(image):\n",
    "    plt.imshow(image, cmap=\"binary\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "def show_reconstructions(model, images=X_valid, n_images=5):\n",
    "    reconstructions = model.predict(images[:n_images])\n",
    "    fig = plt.figure(figsize=(n_images * 1.5, 3))\n",
    "    for image_index in range(n_images):\n",
    "        plt.subplot(2, n_images, 1 + image_index)\n",
    "        plot_image(images[image_index])\n",
    "        plt.subplot(2, n_images, 1 + n_images + image_index)\n",
    "        plot_image(reconstructions[image_index])\n",
    "\n",
    "show_reconstructions(stacked_ae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Variational Autoencoder (VAE)\n",
    "We need a custom sampling layer to sample from the latent distribution $z = \\mu + \\sigma \\cdot \\epsilon$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = keras.backend\n",
    "\n",
    "class Sampling(keras.layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        mean, log_var = inputs\n",
    "        return K.random_normal(tf.shape(log_var)) * K.exp(log_var / 2) + mean\n",
    "\n",
    "codings_size = 10\n",
    "\n",
    "# Encoder\n",
    "inputs = keras.layers.Input(shape=[28, 28])\n",
    "z = keras.layers.Flatten()(inputs)\n",
    "z = keras.layers.Dense(150, activation=\"selu\")(z)\n",
    "z = keras.layers.Dense(100, activation=\"selu\")(z)\n",
    "codings_mean = keras.layers.Dense(codings_size)(z)\n",
    "codings_log_var = keras.layers.Dense(codings_size)(z)\n",
    "codings = Sampling()([codings_mean, codings_log_var])\n",
    "variational_encoder = keras.models.Model(\n",
    "    inputs=[inputs], outputs=[codings_mean, codings_log_var, codings])\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = keras.layers.Input(shape=[codings_size])\n",
    "x = keras.layers.Dense(100, activation=\"selu\")(decoder_inputs)\n",
    "x = keras.layers.Dense(150, activation=\"selu\")(x)\n",
    "x = keras.layers.Dense(28 * 28, activation=\"sigmoid\")(x)\n",
    "outputs = keras.layers.Reshape([28, 28])(x)\n",
    "variational_decoder = keras.models.Model(inputs=[decoder_inputs], outputs=[outputs])\n",
    "\n",
    "# Full VAE\n",
    "_, _, codings = variational_encoder(inputs)\n",
    "reconstructions = variational_decoder(codings)\n",
    "vae = keras.models.Model(inputs=[inputs], outputs=[reconstructions])\n",
    "\n",
    "# Add KL Divergence Loss\n",
    "latent_loss = -0.5 * K.sum(\n",
    "    1 + codings_log_var - K.exp(codings_log_var) - K.square(codings_mean),\n",
    "    axis=-1)\n",
    "vae.add_loss(K.mean(latent_loss) / 784.0)\n",
    "vae.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
    "history = vae.fit(X_train, X_train, epochs=10, batch_size=128, validation_data=(X_valid, X_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Generative Adversarial Network (GAN)\n",
    "We will build a simple DCGAN (Deep Convolutional GAN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codings_size = 30\n",
    "\n",
    "# Generator\n",
    "generator = keras.models.Sequential([\n",
    "    keras.layers.Dense(7 * 7 * 128, input_shape=[codings_size]),\n",
    "    keras.layers.Reshape([7, 7, 128]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2DTranspose(64, kernel_size=5, strides=2, padding=\"same\", activation=\"selu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2DTranspose(1, kernel_size=5, strides=2, padding=\"same\", activation=\"tanh\")\n",
    "])\n",
    "\n",
    "# Discriminator\n",
    "discriminator = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(64, kernel_size=5, strides=2, padding=\"same\",\n",
    "                        activation=keras.layers.LeakyReLU(0.2),\n",
    "                        input_shape=[28, 28, 1]),\n",
    "    keras.layers.Dropout(0.4),\n",
    "    keras.layers.Conv2D(128, kernel_size=5, strides=2, padding=\"same\",\n",
    "                        activation=keras.layers.LeakyReLU(0.2)),\n",
    "    keras.layers.Dropout(0.4),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "gan = keras.models.Sequential([generator, discriminator])\n",
    "\n",
    "# Compile\n",
    "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
    "discriminator.trainable = False # Freeze discriminator during GAN training\n",
    "gan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
    "\n",
    "print(\"GAN defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Custom Training Loop for GAN\n",
    "GANs require a specific training loop: Train discriminator, then train generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dataset = tf.data.Dataset.from_tensor_slices(X_train).shuffle(1000)\n",
    "dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)\n",
    "\n",
    "def train_gan(gan, dataset, batch_size, codings_size, n_epochs=1):\n",
    "    generator, discriminator = gan.layers\n",
    "    for epoch in range(n_epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{n_epochs}\")\n",
    "        for X_batch in dataset:\n",
    "            # Phase 1: Train Discriminator\n",
    "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
    "            generated_images = generator(noise)\n",
    "            X_fake_and_real = tf.concat([generated_images, X_batch], axis=0)\n",
    "            y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n",
    "            discriminator.trainable = True\n",
    "            discriminator.train_on_batch(X_fake_and_real, y1)\n",
    "            \n",
    "            # Phase 2: Train Generator\n",
    "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
    "            y2 = tf.constant([[1.]] * batch_size) # Trick: Generator wants discriminator to say '1' (Real)\n",
    "            discriminator.trainable = False\n",
    "            gan.train_on_batch(noise, y2)\n",
    "\n",
    "train_gan(gan, dataset, batch_size, codings_size, n_epochs=1)\n",
    "\n",
    "# Generate an image\n",
    "noise = tf.random.normal(shape=[1, codings_size])\n",
    "generated_image = generator(noise)\n",
    "plot_image(generated_image[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Step-by-Step Explanation\n",
    "\n",
    "### 1. Autoencoder Compressions\n",
    "**Input:** 784 pixels.\n",
    "**Hidden:** 30 neurons. This forces the model to ignore noise and specific pixel positions, focusing on shapes (e.g., \"a circle at top means head\").\n",
    "**Output:** 784 pixels. The reconstructed image is blurry because the 30-dim vector cannot hold all the details of the original image.\n",
    "\n",
    "### 2. The Reparameterization Trick (VAE)\n",
    "In a VAE, we want to sample $z$ from a Gaussian. But we cannot backpropagate gradients through a random sampling node. \n",
    "**Trick:** $z = \\mu + \\sigma \\odot \\epsilon$. We sample $\\epsilon$ from a standard normal (fixed). Now the randomness is an *input* node (constant during backprop), and $\\mu, \\sigma$ are deterministic nodes that gradients can flow through.\n",
    "\n",
    "### 3. GAN Training Loop Dynamics\n",
    "1.  **Train Discriminator:** We feed it a batch of real images (Label 1) and a batch of fake images generated by the generator (Label 0). It learns to tell them apart.\n",
    "2.  **Train Generator:** We feed noise to the GAN. The generator creates an image, the discriminator classifies it. We want the discriminator to output **1** (Real). So we set the target label to 1. Since the discriminator is frozen, the gradients flow back to update *only* the generator's weights to make the image look more \"real\".\n",
    "\n",
    "### 4. Mode Collapse\n",
    "Sometimes the generator finds one image that fools the discriminator well (e.g., a specific shoe). It then starts producing *only* that shoe. The discriminator learns to block that shoe, so the generator switches to a shirt. They cycle endlessly without learning diverse data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Chapter Summary\n",
    "\n",
    "* **Autoencoders** are excellent for dimensionality reduction and denoising.\n",
    "* **VAEs** add a probabilistic twist, allowing generation of new samples by walking through the latent space.\n",
    "* **GANs** produce the sharpest, most realistic images but are notoriously hard to train (unstable).\n",
    "* **DCGANs** use convolutional layers to scale GANs to image data.\n",
    "* **Generative Learning** is the frontier of AI creativity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
